* The Natural Language Processing Workshop

** 1 - Introduction to Natural Language Processing

   *Natural Language* is a mutually agreed upon set of protocols involving words/sounds that we
   use to communicate with each other.

   *NLP* can be defined as a field of computer science that is concerned with enabling computer
   algorithms to understand, analyze, and generate natural languages.

   *Text analytics* is the method of extracting meaningful insights and answering questions from
   text data *without getting into the semantics* of the language.

   *NLP helps us in understanding the semantics* and the underlying meaning of text.

   NLP works at different *levels*:
   - *Morphological level*: This level deals with understanding word structure and word information.
   - *Lexical level*: This level deals with understanding the part of speech of the word.
   - *Syntactic level*: This level deals with understanding the syntactic analysis of a sentence, or
     parsing a sentence.
   - *Semantic level*: This level deals with understanding the actual meaning of a sentence.
   - *Discourse level*: This level deals with understanding the meaning of a sentence beyond just
     the sentence level, that is, considering the context.
   - *Pragmatic level*: This level deals with using real-world knowledge to understand the sentence.


   NLP can be broadly categorized into two *types*: Natural Language *Understanding* (NLU) and
   Natural Language *Generation* (NLG).

   NLP applies a wide range of *tasks*:
   - *Tokenizing*: splitting a sentence into its constituent parts
   - *Parts-of-speech tagging*: refers to the process of tagging words within sentences as noun,
     verb, adjective, etc.
   - *Stop-word removal*: the most frequently occurring words in any language (articles,
     prepositions, etc)
   - *Normalization*: different variations of text get converted into a standard form.
     There are various ways of normalizing text, such as:
     - *Spelling correction*: one of the most *important* tasks in any NLP (it's time-consuming):
       - *Identify*: the misspelled word.
       - *Suggest*: the correctly spelled word.
     - *Stemming*: convert words into their base forms.
     - *Lemmatization*: convert words to their base grammatical form.

   *Named Entity Recognition (NER)* is the process of extracting important entities, such as
   person names, place names, and organization names, from some given text.

   *Word sense disambiguation* is the process of mapping a word to the sense that it should carry.

   *Sentence boundary detection* is the method of detecting where one sentence ends and another
    begins.

   We can divide an NLP project into several *phases*. These phases are completed in a particular
   order:
   1. *data collection*: use existing data, collect from online repositories, crawling web.
   2. *data processing*: clean the collected data to ensure effectiveness and accuracy:
     - Converting all the text data to lowercase.
     - Stop word removal.
     - Text normalization.
     - Stemming and lemmatization.
   3. *feature extraction*: convert text data into its equivalent numerical form
   4. *model development*: models generally statistical, machine learning-based, deep
       learning-based, or reinforcement learning-based.
   5. *model assessment*: evaluate the performance of the model by comparing its precision,
       recall, and accuracy to others.
   6. *model deployment*: put into production, integrated to existing system or new products.

** Feature Extraction Methods

   There are two main ways to categorize data:
   - *by structure*:
     - *structured*: the most organized form of data (ex: databases, CSV).
     - *semi-structured*: can be transformed into a table (ex: XML, HTML).
     - *unstructured*: difficult to comprehend without loss information (ex: logs, images).
   - *by content*:
     - *text*: written sentences.
     - *image*: pictures.
     - *audio*: voice recordings, music.
     - *video*: a continuous series of images coupled with audio.

   Data cleaning has the objective of extracting meaningful portions from data by eliminating
   unnecessary details (noisy) that can negatively impact the accuracy of the results.

   Machine learning algorithms do not understand textual data directly, it need to be represented
   as numerical form or vectors.

   Features can be classified into two categories:
   - *General features*: do not depend on the content of the text (statistical calculations).
   - *Specific features*: dependent on the meaning of the text (represent the semantics).

   The *Bag of Words (BoW)* model is one of the most popular feature extraction methods:
   - The list of all the words (among all documents) is generated.
   - The document is represented in terms of the presence or absence of all words.

   According to *Zipf's law*, the number of times a word occurs in a corpus is inversely
   proportional to its rank.

   *Term Frequency-Inverse Document Frequency (TFIDF)* is another represention of text as vector,
   it gives more weightage to less frequent (rare) than more frequent (common) words.

   There are different techniques for finding the similarity between texts:
   - *Cosine similarity*: calculating the cosine of the angle between them.
   - *Jaccard similarity*: Calculated as the ratio of the number of terms that are common between
     two text documents to the total number of unique terms present in those texts. Only works on
     BoW vectors.

   The *Lesk algorithm* can be used for words with ambiguous meanings.

   A *word cloud* is a text visualization format in which the size of the word is related to its
   frequency.

   There are many ways of visualizing texts, some popular are:
   - *dependency parse tree*: A data structure for mapping dependencies among sentences. For
     example, the word "help" depends on "the one who helps" and "the ones who are helped".
   - *named entities*: highlight named entities by using different colors.

** Links / references

- https://github.com/nltk/nltk
- https://github.com/sloria/TextBlob
- https://keras.io/
- https://scikit-learn.org/
- https://spacy.io/
- https://matplotlib.org/
- https://github.com/amueller/word_cloud
